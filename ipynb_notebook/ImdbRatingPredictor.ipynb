{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c68ce83b-4530-5c9a-729e-85f2a21c013f"
   },
   "source": [
    "In this Notebook, I tried to predict the Imdb_score values based on the numeric data.\n",
    "Regression model is tried on multiple regression models with and without feature_selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "243d38d4-3598-0842-3cf1-ee83b10bc19d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5043, 28)\n",
      "Index(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n",
      "       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n",
      "       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n",
      "       'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n",
      "       'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n",
      "       'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n",
      "       'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n",
      "       'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Imputer,StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "movies = pd.read_csv(\"../input/movie_metadata.csv\")\n",
    "print (movies.shape)\n",
    "print (movies.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "7b30ea59-eb16-5cb0-1f81-3c2646979ed7"
   },
   "outputs": [],
   "source": [
    "\n",
    "#drop columns which does not seem to have any effect on movie rating\n",
    "\n",
    "#get numeric data for computation and correlation purposes\n",
    "numerical_data = movies.select_dtypes(exclude=[\"object\"])\n",
    "\n",
    "# take out the y value(imdb_score from data)\n",
    "score_imdb= numerical_data[\"imdb_score\"]\n",
    "numerical_data = numerical_data.drop([\"imdb_score\"],axis=1)\n",
    "year_category = numerical_data[\"title_year\"]\n",
    "numerical_data = numerical_data.drop([\"title_year\"],axis=1)\n",
    "numerical_columns = numerical_data.columns\n",
    "# print (numerical_columns.shape)\n",
    "# print (numerical_data[numerical_columns])\n",
    "# print (numerical_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "36a411e8-7bcd-3cda-9476-a41a343224c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['color', 'director_name', 'actor_2_name', 'genres', 'actor_1_name',\n",
      "       'movie_title', 'actor_3_name', 'plot_keywords', 'movie_imdb_link',\n",
      "       'language', 'country', 'content_rating'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#fill missing values and normalize the data\n",
    "imp = Imputer(missing_values=\"NaN\",strategy=\"mean\",axis=0)      #default values\n",
    "numerical_data[numerical_columns] = imp.fit_transform(numerical_data[numerical_columns])\n",
    "# print (numerical_data.describe())\n",
    "\n",
    "#Without StandardScaler, SVR with poly kernel will throw error of large size.\n",
    "#With standard scaling, models has seen improvement in predicting.\n",
    "#knn model is the most beneficiary of standard scaling\n",
    "scaler = StandardScaler()\n",
    "numerical_data[numerical_columns] = scaler.fit_transform(numerical_data[numerical_columns])\n",
    "\n",
    "# print (numerical_data.describe())\n",
    "# print (numerical_data.shape)\n",
    "# numerical_data = pd.DataFrame(numerical_data)\n",
    "# print (numerical_data.describe())\n",
    "\n",
    "#get non_numeric informational content\n",
    "information_data = movies.select_dtypes(include=[\"object\"])\n",
    "print (information_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "2cec7036-0e17-738f-2e4b-2d6384d03273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['num_critic_for_reviews', 'duration', 'num_voted_users', 'num_user_for_reviews', 'movie_facebook_likes'] \n",
      " ['director_facebook_likes', 'gross'] \n",
      " [] \n",
      " ['actor_3_facebook_likes', 'actor_1_facebook_likes', 'cast_total_facebook_likes', 'facenumber_in_poster', 'budget', 'actor_2_facebook_likes', 'aspect_ratio']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#numpy corrcoef returns symmetric metrics of correlation coef\n",
    "#Use -from scipy.stats.stats import pearsonr   print pearsonr(a,b)\n",
    "#check attributes for correlation with movie rating\n",
    "low_covariance_1 = []\n",
    "low_covariance_2 = []\n",
    "low_covariance_15 = []\n",
    "low_covariance_2g = []\n",
    "for x in numerical_columns:\n",
    "    z = (np.corrcoef(numerical_data[x],y=score_imdb))\n",
    "    if(np.fabs(z[0,1]) < 0.1):\n",
    "        low_covariance_1.append(x)\n",
    "    elif(np.fabs(z[0,1]) < 0.15):\n",
    "        low_covariance_15.append(x)\n",
    "    elif(np.fabs(z[0,1])<0.2):\n",
    "        low_covariance_2.append(x)\n",
    "    else:\n",
    "        low_covariance_2g.append(x)\n",
    "\n",
    "print (low_covariance_2g, \"\\n\", low_covariance_2, \"\\n\", low_covariance_15, \"\\n\", low_covariance_1)\n",
    "#attributes with correlation coef >=0.2 . Thyese attributes will help more than other attributes in regression\n",
    "#['num_critic_for_reviews', 'duration', 'num_voted_users', 'num_user_for_reviews', 'movie_facebook_likes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "ffeb65f0-10e5-13d2-26aa-bff7910439ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5043, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest,SelectPercentile,RFE,RFECV,SelectFromModel\n",
    "from sklearn.svm import SVR,SVC\n",
    "from sklearn.linear_model import Lasso\n",
    "#data which has high correlation with imdb_score is selected\n",
    "select_k = SelectKBest(k=8)\n",
    "x_transformed = select_k.fit_transform(numerical_data,y=score_imdb) #x_transformed is numpy array not pandas\n",
    "#sklearn returns numpy array not pandas object\n",
    "print (x_transformed.shape)\n",
    "# print (x_transformed.columns)\n",
    "#print (x_transformed[0,:])\n",
    "# print (numerical_data.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "6b12d4a9-91c1-a7bc-6545-cac0c35a3054"
   },
   "outputs": [],
   "source": [
    "#Taking too much time\n",
    "\n",
    "#print(\"before model selection\")\n",
    "#The underlying estimator SVR has no `coef_` or `feature_importances_` attribute.\n",
    "#  Either pass a fitted estimator to SelectFromModel or call fit before calling transform.\n",
    "#estimator = SVR(kernel=\"linear\").fit(numerical_data,score_imdb)\n",
    "#select_model = SelectFromModel(estimator,prefit=True)\n",
    "#x_transformed = select_model.transform(numerical_data)\n",
    "#print (x_transformed.shape)\n",
    "#print(\"after model selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "a444d940-5046-dc13-b910-d14bb9fe6965"
   },
   "outputs": [],
   "source": [
    "#Taking too much time\n",
    "\n",
    "#RFE use recursive selecting of attributes which is a time counsuming process.\n",
    "#estimator = SVR(kernel=\"linear\")\n",
    "#selector = RFE(estimator)\n",
    "#selector = selector.fit(numerical_data,score_imdb)\n",
    "#print (selector.support_)\n",
    "#print (selector.ranking_)\n",
    "#x_transformed = selector.transform(numerical_data)\n",
    "#print (x_transformed.shape)\n",
    "#print(\"after rfe selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "bbbe1bbf-56d5-12a8-2610-29ff691f8d64"
   },
   "outputs": [],
   "source": [
    "#some global variables to compare and select best of all methods\n",
    "best_on_training_data = {\"training_score\":-10000,\"test_score\":0,\"model\":\"\"}\n",
    "best_on_test_data = {\"training_score\":-10000,\"test_score\":0,\"model\":\"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "79e4477b-826c-1f8f-ffc9-a3cdedbc20d7"
   },
   "outputs": [],
   "source": [
    "#generic utility methods\n",
    "def svm_score(test_y, predict_y):\n",
    "    # convert to numpy array to compare both predict and actual array\n",
    "    # Iris_test_y contain indexes from dataframe(parent)\n",
    "    iris_test_y = np.array(test_y)\n",
    "    diff = 0\n",
    "    total_size = test_y.shape[0]\n",
    "    # print (total_size,test_y.iloc[0],predict_y[0])\n",
    "    for idx in range(total_size):\n",
    "        diff += np.fabs(test_y.iloc[idx]-predict_y[idx])\n",
    "    return diff/total_size\n",
    "\n",
    "def fit_model(model_to_print,model,x_data,y_data):\n",
    "    training_x,test_x,training_Y,test_y = train_test_split(x_data,y_data,test_size=0.001)\n",
    "    model.fit(X=training_x,y=training_Y)\n",
    "    predicted_y = model.predict(test_x)\n",
    "    training_score = model.score(training_x,training_Y)\n",
    "    test_score = model.score(test_x,test_y)\n",
    "    if(training_score > best_on_training_data[\"training_score\"]):\n",
    "        best_on_training_data[\"training_score\"] = training_score\n",
    "        best_on_training_data[\"test_score\"] = test_score\n",
    "        best_on_training_data[\"model\"] = model_to_print\n",
    "    if(training_score > best_on_test_data[\"test_score\"]):\n",
    "        best_on_test_data[\"training_score\"] = training_score\n",
    "        best_on_test_data[\"test_score\"] = test_score\n",
    "        best_on_test_data[\"model\"] = model_to_print\n",
    "    \n",
    "    print  (model_to_print,\"Score on training data: \",training_score)\n",
    "    print  (model_to_print,\"Score on test data: \",test_score, \"\\n\")\n",
    "    # print (model_to_print,\"training\",svm_score(training_Y,model.predict(training_x)))\n",
    "    # print (model_to_print,svm_score(test_y,predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "5968d538-6ff4-2db6-0d30-8208b4974583"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR rbf:  Score on training data:  0.414007695952\n",
      "SVR rbf:  Score on test data:  -0.268168734714 \n",
      "\n",
      "SVR linear:  Score on training data:  0.214206339207\n",
      "SVR linear:  Score on test data:  -1.57263016421 \n",
      "\n",
      "SVR poly:  Score on training data:  0.18743551223\n",
      "SVR poly:  Score on test data:  -0.0126909249893 \n",
      "\n",
      "transformed , svr rbf:  Score on training data:  0.366854084817\n",
      "transformed , svr rbf:  Score on test data:  0.474608461794 \n",
      "\n",
      "transformed , svr linear:  Score on training data:  0.19946099409\n",
      "transformed , svr linear:  Score on test data:  -0.203237619997 \n",
      "\n",
      "transformed , svr poly:  Score on training data:  0.113197591185\n",
      "transformed , svr poly:  Score on test data:  0.0965632659499 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Fit a regression model on numeric data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVR\n",
    "#On complete data without feature extraction\n",
    "svr_model = SVR(kernel='rbf') #default\n",
    "#below kernel is taking infinite time. Hence usign LinearSVR explicitly\n",
    "#svr_linear_model = SVR(kernel=\"linear\") #infinite time(hanging)\n",
    "svr_linear_model = LinearSVR()\n",
    "svr_poly_model = SVR(kernel=\"poly\") #default degree is 3\n",
    "\n",
    "# plt.plot(score_imdb,label=\"original data\")\n",
    "fit_model(\"SVR rbf: \",svr_model,numerical_data,score_imdb)\n",
    "fit_model(\"SVR linear: \",svr_linear_model,numerical_data,score_imdb)\n",
    "\n",
    "#ValueError: Input contains NaN, infinity or a value too large for dtype('float64'). \n",
    "#Without Standard Scaler poly kernel will throw above error.\n",
    "fit_model(\"SVR poly: \",svr_poly_model,numerical_data,score_imdb)\n",
    "\n",
    "#Calling fit on any scikit-learn estimator will forget all the previously seen data\n",
    "#So we can use same models for transformed data also\n",
    "#same model on transformed data with data selection\n",
    "fit_model(\"transformed , svr rbf: \",svr_model,x_transformed,score_imdb)\n",
    "fit_model(\"transformed , svr linear: \",svr_linear_model,x_transformed,score_imdb)\n",
    "fit_model(\"transformed , svr poly: \",svr_poly_model,x_transformed,score_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "8a5ed65c-8027-41cc-173e-37c719c450cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn with k=5:  Score on training data:  0.519168314871\n",
      "knn with k=5:  Score on test data:  0.411150442478 \n",
      "\n",
      "knn with k=10:  Score on training data:  0.438997871996\n",
      "knn with k=10:  Score on test data:  0.206028505393 \n",
      "\n",
      "knn with k=20:  Score on training data:  0.391953636591\n",
      "knn with k=20:  Score on test data:  -0.0957142857143 \n",
      "\n",
      "transformed , knn with k=5:  Score on training data:  0.541758457717\n",
      "transformed , knn with k=5:  Score on test data:  0.06096069869 \n",
      "\n",
      "transformed , knn with k=10:  Score on training data:  0.451760934164\n",
      "transformed , knn with k=10:  Score on test data:  0.572145962733 \n",
      "\n",
      "transformed , knn with k=20:  Score on training data:  0.402546982693\n",
      "transformed , knn with k=20:  Score on test data:  -0.187804347826 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#using knn regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "default_knn = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_10 = KNeighborsRegressor(n_neighbors=10)\n",
    "knn_20 = KNeighborsRegressor(n_neighbors=20)\n",
    "\n",
    "fit_model(\"knn with k=5: \",default_knn,numerical_data,score_imdb)\n",
    "fit_model(\"knn with k=10: \",knn_10,numerical_data,score_imdb)\n",
    "fit_model(\"knn with k=20: \",knn_20,numerical_data,score_imdb)\n",
    "\n",
    "#Calling fit on any scikit-learn estimator will forget all the previously seen data\n",
    "#So we can use same models for transformed data also\n",
    "#same model on transformed data with data selection\n",
    "fit_model(\"transformed , knn with k=5: \",default_knn,x_transformed,score_imdb)\n",
    "fit_model(\"transformed , knn with k=10: \",knn_10,x_transformed,score_imdb)\n",
    "fit_model(\"transformed , knn with k=20: \",knn_20,x_transformed,score_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "e9b16b80-e0da-7408-5eb2-4fb1a73595d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression:  Score on training data:  0.232037036951\n",
      "linear regression:  Score on test data:  0.237807438859 \n",
      "\n",
      "linear regression transformed:  Score on training data:  0.212375819452\n",
      "linear regression transformed:  Score on test data:  -0.0366683311403 \n",
      "\n",
      "Ridge alpha =1: Score on training data:  0.232808330877\n",
      "Ridge alpha =1: Score on test data:  -1.77137058718 \n",
      "\n",
      "Ridge alpha =0.5 : Score on training data:  0.232133125749\n",
      "Ridge alpha =0.5 : Score on test data:  -0.348335046814 \n",
      "\n",
      "Ridge alpha =0.25: Score on training data:  0.232774630802\n",
      "Ridge alpha =0.25: Score on test data:  -0.278798467546 \n",
      "\n",
      "Ridge transformed alpha =1: Score on training data:  0.211910516348\n",
      "Ridge transformed alpha =1: Score on test data:  0.0549173158971 \n",
      "\n",
      "Ridge transformed alpha =0.5 : Score on training data:  0.212288327011\n",
      "Ridge transformed alpha =0.5 : Score on test data:  -0.00359409235113 \n",
      "\n",
      "Ridge transformed alpha =0.25: Score on training data:  0.212048271755\n",
      "Ridge transformed alpha =0.25: Score on test data:  0.236642638462 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Other regression models\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,Ridge\n",
    "\n",
    "linear_reg = LinearRegression()\n",
    "fit_model(\"linear regression: \",linear_reg,numerical_data,score_imdb)\n",
    "\n",
    "#Calling fit on any scikit-learn estimator will forget all the previously seen data\n",
    "#So we can use same models for transformed data also\n",
    "fit_model(\"linear regression transformed: \",linear_reg,x_transformed,score_imdb)\n",
    "\n",
    "#Ridge regression addresses some of the problems of Ordinary Least Squares by imposing a penalty on the size of coefficients.\n",
    "#alpha is the rete of penalty\n",
    "ridge_1 = Ridge(alpha=1.0)\n",
    "ridget_point_5 = Ridge(alpha=0.5)\n",
    "ridget_point_25 = Ridge(alpha=0.25)\n",
    "fit_model(\"Ridge alpha =1:\",ridge_1,numerical_data,score_imdb)\n",
    "fit_model(\"Ridge alpha =0.5 :\",ridget_point_5,numerical_data,score_imdb)\n",
    "fit_model(\"Ridge alpha =0.25:\",ridget_point_25,numerical_data,score_imdb)\n",
    "\n",
    "#Calling fit on any scikit-learn estimator will forget all the previously seen data\n",
    "#So we can use same models for transformed data also\n",
    "fit_model(\"Ridge transformed alpha =1:\",ridge_1,x_transformed,score_imdb)\n",
    "fit_model(\"Ridge transformed alpha =0.5 :\",ridget_point_5,x_transformed,score_imdb)\n",
    "fit_model(\"Ridge transformed alpha =0.25:\",ridget_point_25,x_transformed,score_imdb)\n",
    "\n",
    "#By plotting the distribution against predicted values. You can see that values are in the middle range(5,7) and have a peak at 6.\n",
    "#While the original distribution is more randomly distributed.\n",
    "#Values of score returns the mean deviation from actual score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "af87e3c7-e8c2-09ff-957b-9876e438cf45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model on trainging score is :\n",
      "training_score:  0.541758457717\n",
      "test_score: 0.06096069869\n",
      "model:  transformed , knn with k=5: \n",
      "\n",
      "\n",
      "\n",
      "best model on test score is :\n",
      "training_score:  0.451760934164\n",
      "test_score: 0.572145962733\n",
      "model:  transformed , knn with k=10: \n"
     ]
    }
   ],
   "source": [
    "#Let's check best models on trainging data\n",
    "print (\"best model on trainging score is :\")\n",
    "print (\"training_score: \", best_on_training_data[\"training_score\"])\n",
    "print (\"test_score:\", best_on_training_data[\"test_score\"])\n",
    "print (\"model: \", best_on_training_data[\"model\"])\n",
    "\n",
    "\n",
    "print (\"\\n\\n\\nbest model on test score is :\")\n",
    "print (\"training_score: \", best_on_test_data[\"training_score\"])\n",
    "print (\"test_score:\", best_on_test_data[\"test_score\"])\n",
    "print (\"model: \", best_on_test_data[\"model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "210bfdd9-9775-9ece-806a-9b02eccf6325"
   },
   "source": [
    "**Conclusion** :-\n",
    "\n",
    " - KNN scores better than SVM, linear regression and ridge.  Linear Regression and Ridge scores least among all. \n",
    " - Standard scaling of data increases the score on average. Most of time, increasing the value o K in KNN increases the score. \n",
    " - Still, Accuracy of system is very low. Mean deviation of test data from original data is in the range [0.5,0.9].\n",
    " - IMDB_Score predicted by the model are concentrated in the mid region of score. Most scores are in the range [5,7] with peak around 6.\n",
    " - Most models doesn't predict any value less than 5 and more than 7. "
   ]
  }
 ],
 "metadata": {
  "_change_revision": 85,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
